# Lab01Blockchain

### 1. Tá»•ng quan
Dá»± Ã¡n nÃ y mÃ´ phá»ng má»™t cá»¥m RAFT 5 node (má»—i node cháº¡y riÃªng má»™t process) dÃ¹ng **gRPC** Ä‘á»ƒ trao Ä‘á»•i RPC. Má»¥c tiÃªu: triá»ƒn khai leader election, log replication, commit báº±ng Ä‘a sá»‘ vÃ  kiá»ƒm tra tÃ­nh bá»n vá»¯ng (durability) khi restart.

---
1. YÃªu cáº§u & chuáº©n bá»‹ mÃ´i trÆ°á»ng (Windows)
Python 3.11 (recommend) vÃ  pip.
Táº¡o virtual environment vÃ  kÃ­ch hoáº¡t (PowerShell)
  python -m venv .venv
  .\.venv\Scripts\Activate.ps1
CÃ i dependencies:
  pip install grpcio grpcio-tools pytest
Dá»n dá»¯ liá»‡u/logs (nÃªn lÃ m trÆ°á»›c khi cháº¡y test durability):
  Remove-Item -Recurse -Force .\data
  Remove-Item node-*.log -Force
  Remove-Item -Recurse -Force .\artifacts
  New-Item -ItemType Directory -Path data,artifacts
(Náº¿u xÃ i CMD thÃ¬ cháº¡y lá»‡nh: rmdir /S /Q logs rmdir /S /Q artifacts mkdir logs mkdir artifacts)
2. Kiá»ƒm tra port (báº¯t buá»™c trÆ°á»›c khi start cluster trÃªn CI)
Project sá»­ dá»¥ng cÃ¡c port gRPC máº·c Ä‘á»‹nh 5001..5005 vÃ  HTTP status 6001..6005.
Cháº¡y script kiá»ƒm tra port:
  python tools/check_ports.py
Náº¿u cÃ³ port bá»‹ chiáº¿m, kill tiáº¿n trÃ¬nh tÆ°Æ¡ng á»©ng (Windows):
  taskkill /PID <pid> /F
Ghi chÃº: `start_cluster.py` thá»±c hiá»‡n preflight kiá»ƒm tra port; dÃ¹ng `--force` Ä‘á»ƒ bá» kiá»ƒm tra (chá»‰ dÃ¹ng debug local).
3. CÃ¡ch start node vÃ  cá»¥m node
Start má»™t node trong process riÃªng (recommended):
  python start_node.py 1
Start toÃ n bá»™ cluster (máº·c Ä‘á»‹nh 5 node) báº±ng script orchestrator (má»—i node lÃ  process riÃªng):
  python start_cluster.py
  # Bá» preflight port check (debug local):
  python start_cluster.py --force
Cháº¡y nhiá»u node trong cÃ¹ng má»™t process (phá»¥c vá»¥ phÃ¡t triá»ƒn):
  python run_node.py
Dá»«ng táº¥t cáº£ node (script helper):
  python tools/stop_all_nodes.py
4. Kiá»ƒm tra tráº¡ng thÃ¡i node & admin endpoints (HTTP)
Má»—i node cháº¡y má»™t HTTP status server táº¡i gRPC_port + 1000. VÃ­ dá»¥ node gRPC 127.0.0.1:5001 -> status http://127.0.0.1:6001/state.
CÃ¡c endpoint há»¯u dá»¥ng (Ä‘Æ°á»£c implement trong RaftNode.start_status_server):
GET /state â€” tráº£ JSON gá»“m: role, leader_id, term, log_len, commit_index, last_applied, blackholed_peers, kv_snapshot, next_index, match_index, replication_errors.
GET	/admin/disconnect?peers=ID1,ID2 â€” node sáº½ thÃªm peer vÃ o blackholed_peers vÃ  bá» qua replicate tá»›i peer Ä‘Ã³.
GET	/admin/reconnect?peers=ID1,ID2 â€” loáº¡i peer khá»i blackholed_peers.
GET	/admin/clear â€” xÃ³a má»i blackhole.
GET	/admin/shutdown â€” táº¯t node (gá»i graceful stop).
GET	/admin/setterm?term=NN â€” Ä‘áº·t current_term (bá»‹ giá»›i háº¡n: tá»« chá»‘i giÃ¡ trá»‹ lá»›n quÃ¡ >=1000).
VÃ­ dá»¥ PowerShell:
Invoke-RestMethod "http://127.0.0.1:6001/state"
Invoke-RestMethod "http://127.0.0.1:6001/admin/disconnect?peers=2,3"
Invoke-RestMethod "http://127.0.0.1:6001/admin/reconnect?peers=2,3"
Invoke-RestMethod "http://127.0.0.1:6001/admin/shutdown"
5. Gá»­i lá»‡nh tá»« client
DÃ¹ng client CLI wrapper:
python raft_client.py set mykey 123
  # hoáº·c (há»— trá»£ tÃªn file cÅ©):
  python raft_cilent.py set mykey 123
HÃ m chá»§ chá»‘t gá»­i lá»‡nh: raft_client.send_command(command, max_attempts=3, backoff=0.5).
send_command thá»±c hiá»‡n find_leader() (dÃ¹ng /state) rá»“i gá»i ClientAppend RPC (fallback AppendEntries náº¿u server tráº£ UNIMPLEMENTED).
6. CÃ¡ch thay Ä‘á»•i sá»‘ node / ports / topology
Má»Ÿ file cáº¥u hÃ¬nh: [config.py](config.py)
Sá»­a NODES (dict) theo Ä‘á»‹nh dáº¡ng node_id: "host:port" (vÃ­ dá»¥ thÃªm 6: "127.0.0.1:5006").
NUM_NODES, ALL_NODES vÃ  MAJORITY Ä‘Æ°á»£c tÃ­nh tá»± Ä‘á»™ng tá»« NODES.
Sau khi chá»‰nh NODES:
Äáº£m báº£o cÃ¡c port má»›i khÃ´ng trÃ¹ng (dÃ¹ng tools/check_ports.py).
Restart toÃ n cluster (kill tiáº¿n trÃ¬nh cÅ©, sau Ä‘Ã³ python start_cluster.py).
LÆ°u Ã½: code hiá»‡n táº¡i giáº£ Ä‘á»‹nh cÃ¡c node id lÃ  liÃªn tiáº¿p 1..N á»Ÿ nhiá»u script; náº¿u thay Ä‘á»•i phá»©c táº¡p hÆ¡n (vÃ­ dá»¥ id khÃ´ng liÃªn tiáº¿p), kiá»ƒm tra `start_cluster.py` vÃ  `tests` Ä‘á»ƒ Ä‘áº£m báº£o tÆ°Æ¡ng thÃ­ch.
7. MÃ´ phá»ng lá»—i / nÃºt Ä‘á»™c háº¡i (Byzantine)
Partition / blackhole: dÃ¹ng /admin/disconnect trÃªn node A Ä‘á»ƒ khiáº¿n node A bá» replicate tá»›i má»™t sá»‘ peer. Viá»‡c nÃ y mÃ´ phá»ng máº¥t káº¿t ná»‘i má»™t chiá»u.
Shutdown node: /admin/shutdown hoáº·c kill PID.
Ã‰p term Ä‘á»ƒ kÃ­ch thÃ­ch election: /admin/setterm?term=NN.
pBFT demo (mÃ´ phá»ng Byzantine node):
File demo: run_pbft_node.py (táº¡o PBFTNode vá»›i byzantine=(i == 3) trong vÃ­ dá»¥).
Äá»ƒ thay node gian láº­n, sá»­a run_pbft_node.py hoáº·c pbft_node.py.
8. Persistence & durability
KV store file-backed: má»—i node lÆ°u dá»¯ liá»‡u á»Ÿ data/node_<ID>.json báº±ng class KVStore (file: kv_store.py).
HÃ m: KVStore.set(key, value) vÃ  KVStore.get(key).
Durability test (ká»‹ch báº£n test sáºµn cÃ³): [tests/test_durability.py](tests/test_durability.py)
MÃ´ táº£: start cluster, gá»­i set dur_key 42, kill PIDs, restart cluster, kiá»ƒm tra dur_key tá»“n táº¡i trong kv_snapshot tráº£ bá»Ÿi /state.
Cháº¡y báº±ng:
python -m pytest tests/test_durability.py::test_durability -q
9. File log & artifacts
Logs cá»§a node khi start báº±ng start_node.py: node-1.log, node-2.log, ...
Khi test tháº¥t báº¡i, tests/test_durability.py cÃ³ helper dump_logs() Ä‘á»ƒ copy logs vÃ o artifacts/<timestamp>_reason/.
10. CÃ¡c bÆ°á»›c cháº¡y cá»¥ thá»ƒ (step-by-step)
Má»Ÿ PowerShell, di chuyá»ƒn vÃ o thÆ° má»¥c project.
Táº¡o vÃ  kÃ­ch hoáº¡t venv (nhÆ° á»Ÿ má»¥c 1).
(CI) Cháº¡y python tools/check_ports.py Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c port 5001..5005 vÃ  6001..6005 trá»‘ng.
Khá»Ÿi cá»¥m 5 node:
  python start_cluster.py
Hoáº·c start 1 node Ä‘á»ƒ debug:
  python start_node.py 1
XÃ¡c minh tráº¡ng thÃ¡i node (vÃ­ dá»¥ node 1):
  Invoke-RestMethod "http://127.0.0.1:6001/state"
Gá»­i lá»‡nh vÃ­ dá»¥:
  python raft_client.py set example 100
Kiá»ƒm tra kv_snapshot trong /state cá»§a cÃ¡c node Ä‘á»ƒ xÃ¡c nháº­n commit.
MÃ´ phá»ng fault: táº¯t leader báº±ng /admin/shutdown hoáº·c blackhole follower báº±ng /admin/disconnect.
Cháº¡y test tá»•ng quÃ¡t, cháº¡y test durability vÃ  pBFT:
Má»Ÿ terminal (Powershell/CMD) má»›i vÃ  cd vÃ o thÆ° má»¥c chá»©a Ä‘á»“ Ã¡n
Kill toÃ n bá»™ python vÃ  port cÃ²n dÆ°: taskkill /F /IM python.exe
Dá»n dá»¯ liá»‡u/logs:
  Remove-Item -Recurse -Force .\data
  Remove-Item node-*.log -Force
  Remove-Item -Recurse -Force .\artifacts
  New-Item -ItemType Directory -Path data,artifacts
(Náº¿u xÃ i CMD thÃ¬ cháº¡y lá»‡nh: rmdir /S /Q logs rmdir /S /Q artifacts mkdir logs mkdir artifacts)
KÃ­ch hoáº¡t mÃ´i trÆ°á»ng: .venv\Scripts\activate
Cháº¡y FULL TEST (láº§n 1) python -m pytest -q
Kill python láº§n ná»¯a taskkill /F /IM python.exe
Dá»n sáº¡ch láº¡i dá»¯ liá»‡u/logs:
  Remove-Item -Recurse -Force .\data
  Remove-Item node-*.log -Force
  Remove-Item -Recurse -Force .\artifacts
  New-Item -ItemType Directory -Path data,artifacts
(Náº¿u xÃ i CMD thÃ¬ cháº¡y lá»‡nh: rmdir /S /Q logs rmdir /S /Q artifacts mkdir logs mkdir artifacts)
Cháº¡y DURABILITY (láº§n 2)
python -m pytest tests/test_durability.py::test_durability -q
Test pBFT:
python start_pbft_cluster.py 
pytest -q test_pbft.py
Khi test tháº¥t báº¡i, kiá»ƒm tra artifacts/ vÃ  node-*.log Ä‘á»ƒ phÃ¢n tÃ­ch.


### 8. TÃ i liá»‡u chi tiáº¿t cÃ¡c file & hÃ m (File reference) 

- `config.py`  
  - Má»¥c Ä‘Ã­ch: cáº¥u hÃ¬nh cluster (danh sÃ¡ch node, quorum) vÃ  cÃ¡c háº±ng thá»i gian RAFT (election timeout, heartbeat interval).  
  - Biáº¿n quan trá»ng: `NODES`, `MAJORITY`, `ELECTION_TIMEOUT_MIN`, `ELECTION_TIMEOUT_MAX`, `HEARTBEAT_INTERVAL`.  
  - HÃ m: `random_election_timeout()` Ä‘á»ƒ láº¥y ngáº«u nhiÃªn timeout trong khoáº£ng.

- `raft_state.py`  
  - Má»¥c Ä‘Ã­ch: ná»™i dung state cá»§a má»™t node RAFT (terms, votes, log, commit_index) vÃ  xá»­ lÃ½ logic cá»‘t lÃµi cá»§a RAFT.  
  - Class `RaftState`:
    - `reset_election_timeout(min_timeout, max_timeout)` â€” Ä‘áº·t deadline election má»›i.
    - `election_timeout_reached()` â€” kiá»ƒm tra timeout.
    - `become_follower(term, leader_id=None)`, `become_candidate()`, `become_leader()` â€” chuyá»ƒn vai trÃ² vÃ  cáº­p nháº­t term.
    - `on_request_vote(term, candidate_id)` â€” xá»­ lÃ½ RequestVote RPC (tráº£ vote_granted, term).
    - `on_append_entries(...)` â€” xá»­ lÃ½ AppendEntries RPC (heartbeat hoáº·c replication), Ã¡p log, cáº­p nháº­t commit_index.
    - `debug_status()` â€” in tráº¡ng thÃ¡i ná»™i bá»™ Ä‘á»ƒ debug.
  - Ghi chÃº: há»‡ thá»‘ng **ghi log** khi phÃ¡t hiá»‡n term báº¥t thÆ°á»ng (>=1000); stack traces vÃ  tráº¡ng thÃ¡i chi tiáº¿t Ä‘Æ°á»£c ghi á»Ÿ má»©c DEBUG/WARNING vÃ o `node-*.log` (khÃ´ng in trá»±c tiáº¿p ra stdout).

- `raft_node.py`  
  - Má»¥c Ä‘Ã­ch: thá»±c thi má»™t node RAFT Ä‘áº§y Ä‘á»§ (gRPC server, peer connections, election & heartbeat loops, replication).  
  - Class `RaftNode` (hÃ m ná»•i báº­t):
    - `__init__()` â€” khá»Ÿi táº¡o node, KV store, status HTTP server, apply loop.
    - `ping_peers()` â€” probe nhanh peer báº±ng AppendEntries Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ reachable.
    - `RequestVote(request, context)` / `AppendEntries(request, context)` â€” RPC handlers (náº¿u cháº¡y trá»±c tiáº¿p nhÆ° service).
    - `replicate_to_peer(peer_id, ...)` â€” logic replicate logs tá»›i má»™t peer (fast-path + probe + repair), xá»­ lÃ½ higher-term detection.
    - `commit_by_majority()` â€” commit entries khi Ä‘a sá»‘ Ä‘Ã£ ack.
    - `apply_committed_loop()` â€” apply committed entries vÃ o KV store (persist).
    - `ClientAppend(request, context)` â€” leader-only handler cho client-submitted commands (append -> replicate -> wait commit).
    - `election_loop()`, `start_election()` â€” tiáº¿n hÃ nh election.
    - `heartbeat_loop()` â€” gá»­i heartbeat hoáº·c catch-up replication Ä‘á»‹nh ká»³.
    - `start_status_server()` â€” cháº¡y HTTP `/state` vÃ  `/admin` endpoints (disconnect/reconnect/clear/shutdown/setterm).
  - Telemetry: `next_index`, `match_index`, `replication_errors`, `peer_failure_counts`, `last_heartbeat_ack` giÃºp debug replication health.

- `raft_service.py`  
  - Má»¥c Ä‘Ã­ch: wrapper gRPC service triá»ƒn khai RPCs báº±ng cÃ¡ch sá»­ dá»¥ng `RaftState` (Ä‘Æ°á»£c dÃ¹ng khi dÃ¹ng `RaftService` server class).
  - `RaftService` triá»ƒn khai: `RequestVote`, `AppendEntries`, `ClientAppend` (má»™t sá»‘ tá»‘i Æ°u replication vÃ  log append).

- `raft_rpc.py`  
  - Má»¥c Ä‘Ã­ch: implementation thay tháº¿/Ä‘Æ¡n giáº£n cá»§a cÃ¡c RPC (nháº¹ hÆ¡n) â€” giá»¯ cÃ¡c handler nhÆ° `RequestVote` / `AppendEntries` theo kiá»ƒu trá»±c tiáº¿p tÆ°Æ¡ng tá»± `raft_service`.

- `raft_client.py`  
  - Má»¥c Ä‘Ã­ch: client tiá»‡n Ã­ch Ä‘á»ƒ gá»­i lá»‡nh tá»›i cluster (tÃ¬m leader + ClientAppend fallback AppendEntries).  
  - HÃ m chÃ­nh: `find_leader()` (dÃ¹ng HTTP `/state` Ä‘á»ƒ tÃ¬m leader Ä‘Ã¡ng tin cáº­y), `send_command(command, max_attempts, backoff)` â€” thá»±c thi command tá»›i leader vá»›i retry, fallback khi cáº§n.

- `raft_cilent.py`  
  - Má»¥c Ä‘Ã­ch: CLI tiá»‡n dá»¥ng (tÃªn cÅ©/typo support) â€” gá»i `raft_client.send_command` Ä‘á»ƒ gá»­i lá»‡nh tá»« command line (Ä‘Ã£ sá»­a Ä‘á»ƒ dÃ¹ng client Ä‘Ãºng thay vÃ¬ gá»­i trá»±c tiáº¿p AppendEntries khÃ´ng an toÃ n).

- `kv_store.py`  
  - Má»¥c Ä‘Ã­ch: lÆ°u KV persist (file-backed JSON) vÃ  cung cáº¥p `set/get` Ä‘á»ƒ Ä‘áº£m báº£o durability across restarts.

- `start_node.py`  
  - Má»¥c Ä‘Ã­ch: khá»Ÿi gRPC server cho 1 node trong 1 process (kÃ¨m healthcheck bind Ä‘á»‹a chá»‰ Ä‘á»ƒ trÃ¡nh lá»—i 0.0.0.0 trÃªn Windows). Ghi stdout/stderr vÃ o `node-<id>.log`.

- `start_cluster.py` vÃ  `start_cluster_stagger.py`  
  - Má»¥c Ä‘Ã­ch: script orchestrator Ä‘á»ƒ start 5 node (kÃ¨m preflight port check), in PIDs, Ä‘á»£i `/state` health, chá» leader stability; `--force` Ä‘á»ƒ bá» qua preflight khi debug local.
  - Chá»©c nÄƒng thÃªm: in tail logs náº¿u process exit ngay, set `GRPC_VERBOSITY=error` cho child processes Ä‘á»ƒ giáº£m noise.

- `run_node.py`, `run_smoke.py`  
  - `run_node.py`: helper Ä‘á»ƒ cháº¡y nhiá»u node trong cÃ¹ng process (multi-thread) â€” há»¯u Ã­ch cho phÃ¡t triá»ƒn nhanh.  
  - `run_smoke.py`: script cháº¡y ká»‹ch báº£n smoke test (sanity checks).

- `tools/`  (thÆ° má»¥c helper test/fixture):
  - `tools/check_ports.py` â€” kiá»ƒm tra port 5001..5005 & 6001..6005 cÃ³ bá»‹ chiáº¿m.
  - `tools/fault_tests.py` â€” helper test Ä‘á»ƒ probe states, tÃ¬m leader, kill/restart, simulate faults.
  - `tools/admin.py` â€” wrapper nhá» cho admin HTTP endpoints.
  - `tools/inspect_states.py`, `run_fault_tests.py`, `debug_durability.py`, `stop_all_nodes.py`, `run_leader_crash.py` â€” cÃ¡c ká»‹ch báº£n há»— trá»£ debugging & fault injection.

- `tests/`  
  - `tests/test_durability.py` â€” ká»‹ch báº£n E2E: start cluster, commit key, kill all, restart, verify key persisted. Táº¡o artifacts trÃªn tháº¥t báº¡i.
  - `tests/test_replicate_functional.py` â€” kiá»ƒm tra replicate multi-node scenario (functional).
  - `tests/test_replicate_unit.py` â€” unit tests cho `replicate_to_peer` vÃ  xá»­ lÃ½ higher-term; test nhá» giÃºp tÃ¡ch logic replicate.
  - `tests/test_cli.py` â€” test client/CLI interactions.
  - `tests/test_apply_local.py`, `tests/test_state.py` â€” cÃ¡c unit test khÃ¡c cho apply loop vÃ  state transitions.

- `proto/raft.proto` vÃ  `raft_pb2.py`, `raft_pb2_grpc.py`  
  - MÃ´ táº£: Ä‘á»‹nh nghÄ©a protobuf cho cÃ¡c RPC RAFT (RequestVote, AppendEntries, LogEntry). `pb2` / `pb2_grpc` lÃ  files generated.

- `node-*.log` & `artifacts/`  
  - `node-*.log`: stdout/stderr cá»§a tá»«ng node (ráº¥t há»¯u Ã­ch khi debug start/term/replication issues).
  - `artifacts/`: chá»©a snapshot logs vÃ  file chá»¥p lá»—i khi test tháº¥t báº¡i (timestamped).

- `pbft_block.py`
  - Má»¥c Ä‘Ã­ch: Ä‘á»‹nh nghÄ©a **block tá»‘i giáº£n** dÃ¹ng cho cÃ¡c ká»‹ch báº£n kiá»ƒm tra PBFT (Practical Byzantine Fault Tolerance), chá»§ yáº¿u Ä‘á»ƒ test durability vÃ  logic Ä‘á»“ng thuáº­n. KhÃ´ng chá»©a state phá»©c táº¡p, chá»‰ giá»¯ `height` vÃ  hash.  
  - Class `Block`:  
    - `__init__(height: int, prev_hash: str)` â€” khá»Ÿi táº¡o block vá»›i `height` vÃ  hash cá»§a block trÆ°á»›c (`prev_hash`). Tá»± Ä‘á»™ng tÃ­nh toÃ¡n hash block hiá»‡n táº¡i (`self.hash`).  
    - `_compute_hash()` â€” tÃ­nh toÃ¡n SHA-256 hash dá»±a trÃªn `height` vÃ  `prev_hash`.  
    - `__repr__()` â€” hiá»ƒn thá»‹ block dáº¡ng ngáº¯n gá»n, vÃ­ dá»¥ `Block(height=3, hash=abc123)`, há»¯u Ã­ch khi debug logs.  

- `pbft_message.py`
  - Má»¥c Ä‘Ã­ch: Ä‘á»‹nh nghÄ©a cÃ¡c **message types** vÃ  **class message** cÆ¡ báº£n cho PBFT, dÃ¹ng Ä‘á»ƒ broadcast block giá»¯a cÃ¡c node trong quÃ¡ trÃ¬nh test.  
  - Message Types:  
    - `PRE_PREPARE` â€” bÆ°á»›c chuáº©n bá»‹ trÆ°á»›c khi commit block.  
    - `PREPARE` â€” bÆ°á»›c chuáº©n bá»‹ Ä‘á»“ng thuáº­n tá»« Ä‘a sá»‘ node.  
    - `COMMIT` â€” bÆ°á»›c commit block khi Ä‘a sá»‘ node Ä‘á»“ng thuáº­n.  
  - Class `PBFTMessage`:  
    - `__init__(msg_type: str, block: Any, sender: int)` â€” khá»Ÿi táº¡o message vá»›i loáº¡i (`msg_type`), block Ä‘Ã­nh kÃ¨m (`block`) vÃ  node gá»­i (`sender`).  
    - `__repr__()` â€” hiá»ƒn thá»‹ dáº¡ng ngáº¯n gá»n: `PBFTMessage(type=PREPARE, height=3, sender=1)`, há»¯u Ã­ch khi debug logs. 

- `pbft_node.py`
  - Má»¥c Ä‘Ã­ch: triá»ƒn khai node PBFT Ä‘Æ¡n giáº£n, há»— trá»£ cÃ¡c ká»‹ch báº£n **primary**, **Byzantine**, vÃ  **durability tests**. DÃ¹ng Ä‘á»ƒ simulate broadcast message, voting, vÃ  commit block giá»¯a cÃ¡c node.  
  - Class `PBFTNode`:
    - `__init__(node_id: int, total_nodes: int, is_primary: bool = False, byzantine: bool = False)`  
      - Khá»Ÿi táº¡o node vá»›i `node_id`, tá»•ng sá»‘ node `total_nodes`, cá» `is_primary`, vÃ  cá» `byzantine`.  
      - TÃ­nh toÃ¡n `f = (n-1)//3` cho quorum BFT.  
      - Khá»Ÿi táº¡o cÃ¡c cáº¥u trÃºc lÆ°u votes (`prepare_votes`, `commit_votes`), block finalized, blacklist, v.v.  
    - `connect(peers: List[PBFTNode])` â€” káº¿t ná»‘i node vá»›i danh sÃ¡ch peers Ä‘á»ƒ broadcast message.  
    - `broadcast(msg: PBFTMessage)` â€” gá»­i message Ä‘áº¿n táº¥t cáº£ peers (ngoáº¡i trá»« báº£n thÃ¢n).  
    - `start_pbft(block: Any)` â€” entry point cá»§a primary node Ä‘á»ƒ báº¯t Ä‘áº§u PRE-PREPARE cho block má»›i.  
    - `receive(msg: PBFTMessage)` â€” nháº­n message vÃ  dispatch tá»›i handler tÆ°Æ¡ng á»©ng (`_on_pre_prepare`, `_on_prepare`, `_on_commit`).  
    - `_on_pre_prepare(msg: PBFTMessage)` â€” xá»­ lÃ½ PRE-PREPARE message, broadcast PREPARE tá»›i peers, kiá»ƒm tra quorum.  
    - `_on_prepare(msg: PBFTMessage)` â€” xá»­ lÃ½ PREPARE message, cáº­p nháº­t votes, kiá»ƒm tra quorum.  
    - `_check_prepare_quorum(block: Any)` â€” kiá»ƒm tra náº¿u Ä‘Ã£ Ä‘á»§ quorum PREPARE (â‰¥ 2f+1), gá»­i COMMIT vÃ  gá»i `_check_commit_quorum`.  
    - `_on_commit(msg: PBFTMessage)` â€” xá»­ lÃ½ COMMIT message, cáº­p nháº­t votes vÃ  kiá»ƒm tra quorum commit.  
    - `_check_commit_quorum(block: Any)` â€” kiá»ƒm tra náº¿u Ä‘á»§ quorum COMMIT, Ä‘Ã¡nh dáº¥u block finalized vÃ  log thÃ´ng tin.  
- `start_pbft_cluster.py`:
  - Má»¥c Ä‘Ã­ch: entry point Ä‘á»ƒ **khá»Ÿi cháº¡y má»™t PBFT node** trong má»™t process.

---

### 9. Cáº¥u trÃºc thÆ° má»¥c
## ğŸ“‚ Project Structure

```text
LAB01BLOCKCHAIN/
â”œâ”€â”€ proto/           
â”œâ”€â”€ scripts/                
â”œâ”€â”€ tests/                                                
â”œâ”€â”€ tools/                  
â”‚
â”œâ”€â”€ pbft_*.py               
â”‚   â”œâ”€â”€ pbft_block.py       
â”‚   â”œâ”€â”€ pbft_message.py     
â”‚   â””â”€â”€ pbft_node.py        
â”‚
â”œâ”€â”€ raft_*.py               
â”‚   â”œâ”€â”€ raft_node.py        
â”‚   â”œâ”€â”€ raft_client.py      
â”‚   â”œâ”€â”€ raft_state.py       
â”‚   â””â”€â”€ raft_service.py     
â”‚
â”œâ”€â”€ start_*.py              
â”‚   â”œâ”€â”€ start_cluster.py   
â”‚   â”œâ”€â”€ start_node.py   
â”‚   â”œâ”€â”€ start_pbft_cluster.py 
â”‚   â””â”€â”€ start_cluster_stagger.py 
â”‚
â”œâ”€â”€ run_*.py                
â”‚   â”œâ”€â”€ run_node.py         
â”‚   â”œâ”€â”€ run_smoke.py 
â”‚   â””â”€â”€ run_pbft_node.py         
â”‚
â”œâ”€â”€ config.py               
â”œâ”€â”€ kv_store.py             
â”œâ”€â”€ probe_state.py                       
â””â”€â”€ README.md               